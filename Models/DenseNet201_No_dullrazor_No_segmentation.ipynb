{"cells":[{"cell_type":"markdown","metadata":{"id":"oTY2nsttIsSB"},"source":["# DenseNet 201 model for cancer detection on the HAM10000 dataset"]},{"cell_type":"markdown","metadata":{"id":"kGJ7aLO_IyFw"},"source":["## import necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4133,"status":"ok","timestamp":1730965433694,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"xwd96pkvCrkh"},"outputs":[],"source":["import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow.keras.applications import DenseNet201\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.preprocessing import LabelEncoder\n","\n","import os\n","import json"]},{"cell_type":"markdown","metadata":{"id":"HLyVeDAj10ul"},"source":["## Load preprocessed dataset (resized 128x128, no segmentation)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3399,"status":"ok","timestamp":1730965437089,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"Xzv46uiIBsnp","outputId":"d9c50b63-3410-4063-b353-ecfc926800ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2690,"status":"ok","timestamp":1730965439775,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"IcFHGVHbCtKO"},"outputs":[],"source":["X = np.load('/content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/X_NO_dullrazor_NO_segmentation_128.npy')/255\n","y = np.load('/content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/y_NO_dullrazor_NO_segmentation_128.npy')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1730965439776,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"JRUDp6bBdEJZ"},"outputs":[],"source":["def normalize_images_imagenet(X):\n","    \"\"\"\n","    Normalize images using ImageNet mean and std\n","    \"\"\"\n","    #ImageNet normalization\n","    mean = [0.485, 0.456, 0.406]\n","    std = [0.229, 0.224, 0.225]\n","\n","    for i in range(3):\n","        X[:,:,:,i] = (X[:,:,:,i] - mean[i]) / std[i]\n","\n","    return X"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3093,"status":"ok","timestamp":1730965442866,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"Ei_y_19CddBv"},"outputs":[],"source":["X = normalize_images_imagenet(X)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1730965442866,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"h5pyr0FHC2Yq","outputId":"3a90e83a-e4ab-4d36-ac68-2a9adc4075df"},"outputs":[{"data":{"text/plain":["(10010, 128, 128, 3)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["X.shape"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1730965442866,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"3lx3_1spDGxG","outputId":"5b073a6f-6ac0-4cb1-9e11-51fb50476723"},"outputs":[{"data":{"text/plain":["(10010,)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["y.shape"]},{"cell_type":"markdown","metadata":{"id":"VZdWYXVNSr_H"},"source":["## Define model directories"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1730965442866,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"4zCV51Q4Sxkj"},"outputs":[],"source":["frozen_model_dir = \"/content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/\"\n","fine_tuned_model_dir = \"/content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/\""]},{"cell_type":"markdown","metadata":{"id":"4dYOsO4oR-hV"},"source":["## Prepare labels with One-Hot encoding"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1730965442866,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"mY789qwWR8xE"},"outputs":[],"source":["def prepare_labels(labels, model_dir):\n","    \"\"\"Convert string labels to one-hot encoding\"\"\"\n","    #create and fit label encoder\n","    label_encoder = LabelEncoder()\n","    numeric_labels = label_encoder.fit_transform(labels)\n","\n","    #save label encoder classes so we can use them later for interpretation\n","    label_mapping = dict(zip(label_encoder.classes_,\n","                            range(len(label_encoder.classes_))))\n","    with open(os.path.join(model_dir, 'label_mapping_128.json'), 'w') as f:\n","        json.dump(label_mapping, f)\n","\n","    #one-hot encoding the numeric-encoded classes\n","    one_hot_labels = tf.keras.utils.to_categorical(numeric_labels)\n","\n","    #Print mapping for verification\n","    print(\"Label mapping:\")\n","    for label, idx in label_mapping.items():\n","        print(f\"{label}: {idx}\")\n","\n","    return one_hot_labels, label_encoder"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1730965442866,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"usPZTbWrSEYZ","outputId":"9fe1ff1f-2cf9-45fd-a96b-feacdd65a85f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Label mapping:\n","akiec: 0\n","bcc: 1\n","bkl: 2\n","df: 3\n","mel: 4\n","nv: 5\n","vasc: 6\n"]}],"source":["y_encoded, label_encoder = prepare_labels(y, frozen_model_dir)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1730965442866,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"RST_ewYaTngs","outputId":"64bdde15-29d8-4fb6-cde8-2d5dd7df4142"},"outputs":[{"data":{"text/plain":["array([[0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 0., 0., 0., 1., 0.],\n","       [0., 1., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 1., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 0., 0., 0., 1., 0.]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["y_encoded[0:10]"]},{"cell_type":"markdown","metadata":{"id":"2ujF6rPBLFHx"},"source":["### Handle class imbalance -\u003e weigthed loss"]},{"cell_type":"markdown","metadata":{"id":"PhoIjkCBNBzW"},"source":["first, compute class weights"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1730965442866,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"qfdJrYjBLEYJ"},"outputs":[],"source":["#Normally, we would not compute the class weights over the entire dataset (data leakage), but here we will use a class balanced split so it doesn't really matter.\n","def calculate_class_weights(y_encoded):\n","    \"\"\"\n","    Calculate class weights from original string labels\n","\n","    Parameters:\n","    label_encoder: LabelEncoder object which served to encode the original labels\n","    original_labels: array of original string labels\n","\n","    Returns:\n","    dict: mapping of numerical indices to weights\n","    \"\"\"\n","    #Use label encoder to get numerical labels\n","    numerical_labels = np.argmax(y_encoded, axis=1)\n","\n","    #Calculate weights\n","    weights = compute_class_weight(\n","        class_weight='balanced',\n","        classes=np.unique(numerical_labels),\n","        y=numerical_labels\n","    )\n","\n","    #Create dictionary mapping class indices to weights\n","    class_weights = dict(zip(range(len(weights)), weights))\n","\n","    return class_weights"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1730965442866,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"7AUiUvErYI9j","outputId":"4c45e82b-7f79-43b7-9621-a3fa4c6f4fed"},"outputs":[{"data":{"text/plain":["{0: 4.386503067484663,\n"," 1: 2.782101167315175,\n"," 2: 1.3035551504102096,\n"," 3: 12.434782608695652,\n"," 4: 1.2848158131176999,\n"," 5: 0.21333731165149933,\n"," 6: 10.070422535211268}"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["#try the function\n","calculate_class_weights(y_encoded)"]},{"cell_type":"markdown","metadata":{"id":"WQ1cxS6pI5mT"},"source":["## We're going to do a two phase training approach:\n","* Initial training with frozen base model\n","* Fine-tuning of the last 30 layers"]},{"cell_type":"markdown","metadata":{"id":"jvOScpjTK906"},"source":["### Create a DenseNet model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n-f18HJYDIb_"},"outputs":[],"source":["def create_densenet_model(num_classes, input_shape=(128, 128, 3)):\n","    \"\"\"\n","    Create a DenseNet201 model with custom top layers for melanoma detection\n","    \"\"\"\n","    #Load the pre-trained DenseNet201 model without top layers\n","    base_model = DenseNet201(\n","        weights='imagenet',\n","        include_top=False,\n","        input_shape=input_shape\n","    )\n","\n","    #Freeze the base model layers\n","    base_model.trainable = False\n","\n","    #Add custom top layers\n","    x = base_model.output\n","    x = Flatten()(x)\n","    x = Dropout(0.25)(x)\n","\n","    x = Dense(512, activation='relu')(x)\n","    x = BatchNormalization()(x) #Good habit apparently, It normalizes the activations of each layer, making their means close to 0 and standard deviations close to 1\n","    x = Dropout(0.5)(x)\n","\n","    x = Dense(128, activation='relu')(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.5)(x)\n","\n","    #Output layer\n","    predictions = Dense(num_classes, activation='softmax')(x)\n","\n","    #Create the full model\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"z6Hh7n8VPDHk"},"source":["## Train model with frozen base DenseNet201"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6S68n2LJrju"},"outputs":[],"source":["def train_model(X, y_encoded, batch_size=32, epochs=50, model_dir='model_checkpoints'):\n","    \"\"\"\n","    Train the model with class weighting and proper checkpoint saving\n","    \"\"\"\n","    #Create model directory if it doesn't exist\n","    os.makedirs(model_dir, exist_ok=True)\n","\n","    #Calculate class weights\n","    class_weights = calculate_class_weights(y_encoded)\n","    print(\"Class weights:\", class_weights)\n","\n","    ##---Data splitting: we want a 75, 20, 5 train/test/validation split\n","    X_train_val, X_test, y_train_val, y_test = train_test_split(\n","        X, y_encoded,\n","        test_size=0.20,\n","        random_state=42, #for reproductibility\n","        stratify=y_encoded\n","    )\n","\n","      #Then split remaining data into train and validation (val is 5% of total)\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X_train_val, y_train_val,\n","        test_size=0.0625,  #0.05/0.80 to get 5% of total data\n","        random_state=42,\n","        stratify=y_train_val\n","    )\n","\n","    #initialte DenseNet model\n","    model = create_densenet_model(num_classes=y_encoded.shape[1])\n","\n","    #compile with optimizers and loss\n","    model.compile(\n","        optimizer=Adam(learning_rate=0.001),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')] #AUC is a very good metric for our problem\n","    )\n","\n","    #Define callbacks\n","    checkpoint_path = os.path.join(model_dir, 'densenet201_ph1_128_no_dullrazor_no_segmentation.keras')\n","    callbacks = [\n","        ModelCheckpoint( #save best model at each iteration, because the tensorflow built-in functionnality doesn't work\n","            checkpoint_path,\n","            monitor='val_auc',\n","            save_best_only=True,\n","            mode='max',\n","            verbose=1\n","        ),\n","        EarlyStopping( #avoid overfitting\n","            monitor='val_auc', #here we monitor the AUC\n","            patience=6,\n","            mode=\"max\",\n","            verbose=1\n","        ),\n","        #Set a learning rate annealer\n","        ReduceLROnPlateau(monitor='val_auc',\n","                          patience=3,\n","                          verbose=1,\n","                          factor=0.5,\n","                          min_lr=0.00001)\n","    ]\n","\n","    #Train the model\n","    history = model.fit(\n","        X_train,\n","        y_train,\n","        batch_size=batch_size,\n","        epochs=epochs,\n","        validation_data=(X_test, y_test),\n","        callbacks=callbacks,\n","        class_weight=class_weights #WEIGHTED LOSS to address class imbalance !\n","    )\n","\n","    #Load the best model\n","    best_model = load_model(checkpoint_path)\n","\n","    return best_model, history"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"geVcircEQalI","outputId":"9a2a43b3-d403-462f-e475-b22e96b1ec4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Class weights: {0: 4.386503067484663, 1: 2.782101167315175, 2: 1.3035551504102096, 3: 12.434782608695652, 4: 1.2848158131176999, 5: 0.21333731165149933, 6: 10.070422535211268}\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m74836368/74836368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n","Epoch 1/50\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.2459 - auc: 0.6197 - loss: 2.4502\n","Epoch 1: val_auc improved from -inf to 0.85720, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_no_dullrazor_no_segmentation.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 164ms/step - accuracy: 0.2460 - auc: 0.6198 - loss: 2.4495 - val_accuracy: 0.5455 - val_auc: 0.8572 - val_loss: 1.3055 - learning_rate: 0.0010\n","Epoch 2/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3868 - auc: 0.7538 - loss: 1.6647\n","Epoch 2: val_auc did not improve from 0.85720\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 46ms/step - accuracy: 0.3869 - auc: 0.7539 - loss: 1.6642 - val_accuracy: 0.5400 - val_auc: 0.8514 - val_loss: 1.3341 - learning_rate: 0.0010\n","Epoch 3/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4765 - auc: 0.8197 - loss: 1.3057\n","Epoch 3: val_auc did not improve from 0.85720\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.4765 - auc: 0.8197 - loss: 1.3057 - val_accuracy: 0.5275 - val_auc: 0.8560 - val_loss: 1.3297 - learning_rate: 0.0010\n","Epoch 4/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5238 - auc: 0.8582 - loss: 1.0715\n","Epoch 4: val_auc improved from 0.85720 to 0.89445, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_no_dullrazor_no_segmentation.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.5238 - auc: 0.8582 - loss: 1.0717 - val_accuracy: 0.5869 - val_auc: 0.8944 - val_loss: 1.1207 - learning_rate: 0.0010\n","Epoch 5/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5326 - auc: 0.8662 - loss: 0.9867\n","Epoch 5: val_auc improved from 0.89445 to 0.91794, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_no_dullrazor_no_segmentation.keras\n","\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.5327 - auc: 0.8662 - loss: 0.9867 - val_accuracy: 0.6424 - val_auc: 0.9179 - val_loss: 0.9900 - learning_rate: 0.0010\n","Epoch 6/50\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5817 - auc: 0.8914 - loss: 0.9081\n","Epoch 6: val_auc did not improve from 0.91794\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.5817 - auc: 0.8914 - loss: 0.9080 - val_accuracy: 0.6454 - val_auc: 0.9166 - val_loss: 0.9971 - learning_rate: 5.0000e-04\n","Epoch 7/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6263 - auc: 0.9081 - loss: 0.7904\n","Epoch 7: val_auc improved from 0.91794 to 0.92019, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_no_dullrazor_no_segmentation.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.6263 - auc: 0.9081 - loss: 0.7904 - val_accuracy: 0.6449 - val_auc: 0.9202 - val_loss: 0.9790 - learning_rate: 5.0000e-04\n","Epoch 8/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6398 - auc: 0.9147 - loss: 0.7091\n","Epoch 8: val_auc improved from 0.92019 to 0.92821, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_no_dullrazor_no_segmentation.keras\n","\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.6398 - auc: 0.9147 - loss: 0.7092 - val_accuracy: 0.6653 - val_auc: 0.9282 - val_loss: 0.9321 - learning_rate: 5.0000e-04\n","Epoch 9/50\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6498 - auc: 0.9203 - loss: 0.6790\n","Epoch 9: val_auc did not improve from 0.92821\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.6498 - auc: 0.9203 - loss: 0.6790 - val_accuracy: 0.6553 - val_auc: 0.9215 - val_loss: 0.9732 - learning_rate: 2.5000e-04\n","Epoch 10/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6621 - auc: 0.9247 - loss: 0.6045\n","Epoch 10: val_auc did not improve from 0.92821\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.6621 - auc: 0.9248 - loss: 0.6046 - val_accuracy: 0.6568 - val_auc: 0.9246 - val_loss: 0.9593 - learning_rate: 2.5000e-04\n","Epoch 11/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6753 - auc: 0.9319 - loss: 0.6013\n","Epoch 11: val_auc improved from 0.92821 to 0.93123, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_no_dullrazor_no_segmentation.keras\n","\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 52ms/step - accuracy: 0.6753 - auc: 0.9319 - loss: 0.6012 - val_accuracy: 0.6608 - val_auc: 0.9312 - val_loss: 0.9198 - learning_rate: 2.5000e-04\n","Epoch 12/50\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6872 - auc: 0.9365 - loss: 0.5595\n","Epoch 12: val_auc did not improve from 0.93123\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.6872 - auc: 0.9365 - loss: 0.5595 - val_accuracy: 0.6653 - val_auc: 0.9302 - val_loss: 0.9246 - learning_rate: 1.2500e-04\n","Epoch 13/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6921 - auc: 0.9400 - loss: 0.5166\n","Epoch 13: val_auc improved from 0.93123 to 0.93474, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_no_dullrazor_no_segmentation.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 52ms/step - accuracy: 0.6921 - auc: 0.9400 - loss: 0.5166 - val_accuracy: 0.6728 - val_auc: 0.9347 - val_loss: 0.8917 - learning_rate: 1.2500e-04\n","Epoch 14/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7005 - auc: 0.9416 - loss: 0.5056\n","Epoch 14: val_auc improved from 0.93474 to 0.93763, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_no_dullrazor_no_segmentation.keras\n","\n","Epoch 14: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 52ms/step - accuracy: 0.7006 - auc: 0.9416 - loss: 0.5056 - val_accuracy: 0.6813 - val_auc: 0.9376 - val_loss: 0.8780 - learning_rate: 1.2500e-04\n","Epoch 15/50\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7205 - auc: 0.9489 - loss: 0.4711\n","Epoch 15: val_auc improved from 0.93763 to 0.93896, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_no_dullrazor_no_segmentation.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.7205 - auc: 0.9489 - loss: 0.4711 - val_accuracy: 0.6888 - val_auc: 0.9390 - val_loss: 0.8628 - learning_rate: 6.2500e-05\n","Epoch 16/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7105 - auc: 0.9472 - loss: 0.5064\n","Epoch 16: val_auc improved from 0.93896 to 0.93951, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_no_dullrazor_no_segmentation.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 52ms/step - accuracy: 0.7105 - auc: 0.9472 - loss: 0.5063 - val_accuracy: 0.6908 - val_auc: 0.9395 - val_loss: 0.8617 - learning_rate: 6.2500e-05\n","Epoch 17/50\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7232 - auc: 0.9508 - loss: 0.4584\n","Epoch 17: val_auc improved from 0.93951 to 0.94042, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_no_dullrazor_no_segmentation.keras\n","\n","Epoch 17: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 52ms/step - accuracy: 0.7232 - auc: 0.9508 - loss: 0.4584 - val_accuracy: 0.6858 - val_auc: 0.9404 - val_loss: 0.8557 - learning_rate: 6.2500e-05\n","Epoch 18/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7143 - auc: 0.9497 - loss: 0.4545\n","Epoch 18: val_auc did not improve from 0.94042\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.7143 - auc: 0.9497 - loss: 0.4545 - val_accuracy: 0.6853 - val_auc: 0.9386 - val_loss: 0.8689 - learning_rate: 3.1250e-05\n","Epoch 19/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7282 - auc: 0.9517 - loss: 0.4356\n","Epoch 19: val_auc improved from 0.94042 to 0.94180, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_no_dullrazor_no_segmentation.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 51ms/step - accuracy: 0.7282 - auc: 0.9517 - loss: 0.4356 - val_accuracy: 0.6938 - val_auc: 0.9418 - val_loss: 0.8475 - learning_rate: 3.1250e-05\n","Epoch 20/50\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7339 - auc: 0.9547 - loss: 0.4383\n","Epoch 20: val_auc did not improve from 0.94180\n","\n","Epoch 20: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.7339 - auc: 0.9547 - loss: 0.4383 - val_accuracy: 0.6918 - val_auc: 0.9402 - val_loss: 0.8591 - learning_rate: 3.1250e-05\n","Epoch 21/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7283 - auc: 0.9526 - loss: 0.4352\n","Epoch 21: val_auc did not improve from 0.94180\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.7283 - auc: 0.9526 - loss: 0.4352 - val_accuracy: 0.6858 - val_auc: 0.9394 - val_loss: 0.8662 - learning_rate: 1.5625e-05\n","Epoch 22/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7322 - auc: 0.9535 - loss: 0.4111\n","Epoch 22: val_auc did not improve from 0.94180\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - accuracy: 0.7322 - auc: 0.9535 - loss: 0.4112 - val_accuracy: 0.6893 - val_auc: 0.9407 - val_loss: 0.8572 - learning_rate: 1.5625e-05\n","Epoch 23/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7288 - auc: 0.9514 - loss: 0.4135\n","Epoch 23: val_auc did not improve from 0.94180\n","\n","Epoch 23: ReduceLROnPlateau reducing learning rate to 1e-05.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - accuracy: 0.7288 - auc: 0.9514 - loss: 0.4135 - val_accuracy: 0.6888 - val_auc: 0.9393 - val_loss: 0.8691 - learning_rate: 1.5625e-05\n","Epoch 24/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7290 - auc: 0.9517 - loss: 0.4261\n","Epoch 24: val_auc improved from 0.94180 to 0.94243, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_no_dullrazor_no_segmentation.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.7290 - auc: 0.9517 - loss: 0.4261 - val_accuracy: 0.6943 - val_auc: 0.9424 - val_loss: 0.8424 - learning_rate: 1.0000e-05\n","Epoch 25/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7196 - auc: 0.9537 - loss: 0.4201\n","Epoch 25: val_auc did not improve from 0.94243\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 46ms/step - accuracy: 0.7197 - auc: 0.9537 - loss: 0.4201 - val_accuracy: 0.6958 - val_auc: 0.9420 - val_loss: 0.8463 - learning_rate: 1.0000e-05\n","Epoch 26/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7284 - auc: 0.9541 - loss: 0.4075\n","Epoch 26: val_auc did not improve from 0.94243\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - accuracy: 0.7284 - auc: 0.9541 - loss: 0.4075 - val_accuracy: 0.6908 - val_auc: 0.9400 - val_loss: 0.8614 - learning_rate: 1.0000e-05\n","Epoch 27/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7365 - auc: 0.9561 - loss: 0.4107\n","Epoch 27: val_auc did not improve from 0.94243\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - accuracy: 0.7365 - auc: 0.9561 - loss: 0.4107 - val_accuracy: 0.6938 - val_auc: 0.9419 - val_loss: 0.8476 - learning_rate: 1.0000e-05\n","Epoch 28/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7330 - auc: 0.9521 - loss: 0.4103\n","Epoch 28: val_auc did not improve from 0.94243\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 46ms/step - accuracy: 0.7331 - auc: 0.9521 - loss: 0.4104 - val_accuracy: 0.6938 - val_auc: 0.9422 - val_loss: 0.8444 - learning_rate: 1.0000e-05\n","Epoch 29/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7260 - auc: 0.9523 - loss: 0.3984\n","Epoch 29: val_auc improved from 0.94243 to 0.94423, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_no_dullrazor_no_segmentation.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.7261 - auc: 0.9523 - loss: 0.3984 - val_accuracy: 0.6978 - val_auc: 0.9442 - val_loss: 0.8262 - learning_rate: 1.0000e-05\n","Epoch 30/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7261 - auc: 0.9538 - loss: 0.4090\n","Epoch 30: val_auc did not improve from 0.94423\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 46ms/step - accuracy: 0.7261 - auc: 0.9538 - loss: 0.4090 - val_accuracy: 0.6948 - val_auc: 0.9432 - val_loss: 0.8367 - learning_rate: 1.0000e-05\n","Epoch 31/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7300 - auc: 0.9529 - loss: 0.4227\n","Epoch 31: val_auc did not improve from 0.94423\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.7300 - auc: 0.9529 - loss: 0.4227 - val_accuracy: 0.6918 - val_auc: 0.9419 - val_loss: 0.8471 - learning_rate: 1.0000e-05\n","Epoch 32/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7388 - auc: 0.9562 - loss: 0.4012\n","Epoch 32: val_auc did not improve from 0.94423\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.7388 - auc: 0.9562 - loss: 0.4012 - val_accuracy: 0.6893 - val_auc: 0.9416 - val_loss: 0.8520 - learning_rate: 1.0000e-05\n","Epoch 33/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7442 - auc: 0.9553 - loss: 0.3912\n","Epoch 33: val_auc did not improve from 0.94423\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.7441 - auc: 0.9553 - loss: 0.3912 - val_accuracy: 0.6978 - val_auc: 0.9434 - val_loss: 0.8363 - learning_rate: 1.0000e-05\n","Epoch 34/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7338 - auc: 0.9555 - loss: 0.3966\n","Epoch 34: val_auc did not improve from 0.94423\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.7338 - auc: 0.9555 - loss: 0.3966 - val_accuracy: 0.6983 - val_auc: 0.9432 - val_loss: 0.8386 - learning_rate: 1.0000e-05\n","Epoch 35/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7374 - auc: 0.9555 - loss: 0.4307\n","Epoch 35: val_auc did not improve from 0.94423\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - accuracy: 0.7374 - auc: 0.9555 - loss: 0.4306 - val_accuracy: 0.6933 - val_auc: 0.9424 - val_loss: 0.8463 - learning_rate: 1.0000e-05\n","Epoch 35: early stopping\n"]}],"source":["best_model_frozen, history_frozen = train_model(X=X, y_encoded=y_encoded, batch_size = 16, epochs = 50, model_dir=frozen_model_dir)"]},{"cell_type":"markdown","metadata":{"id":"A-DKUcZKPQZ8"},"source":["## Fine tune the last 2 blocks of the model"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1730965445891,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"4lWy8a05O7Wd"},"outputs":[],"source":["def fine_tune_model(model, X, y_encoded, batch_size=128, epochs=30, model_dir='model_checkpoints'):\n","    \"\"\"\n","    Fine-tune the model from phase A with class weighting and proper checkpoint saving\n","    \"\"\"\n","    #Create model directory if it doesn't exist\n","    os.makedirs(model_dir, exist_ok=True)\n","\n","    #Calculate class weights\n","    class_weights = calculate_class_weights(y_encoded)\n","\n","    ##---Data splitting: we want a 75, 20, 5 train/test/validation split\n","    X_train_val, X_test, y_train_val, y_test = train_test_split(\n","        X, y_encoded,\n","        test_size=0.20,\n","        random_state=42, #for reproductibility\n","        stratify=y_encoded\n","    )\n","\n","      #Then split remaining data into train and validation (val is 5% of total)\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X_train_val, y_train_val,\n","        test_size=0.0625,  #0.05/0.80 to get 5% of total data\n","        random_state=42,\n","        stratify=y_train_val\n","    )\n","\n","    #Unfreeze all layers\n","    for layer in model.layers:\n","        layer.trainable = True\n","\n","    #Recompile with a lower learning rate\n","    model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), ##Much lower learning rate for fine-tuning\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n","    )\n","\n","    #Define callbacks\n","    checkpoint_path = os.path.join(model_dir, 'densenet201_ph2_128_no_dullrazor_no_segmentation.keras')\n","    callbacks = [\n","        ModelCheckpoint(\n","            checkpoint_path,\n","            monitor='val_auc',\n","            save_best_only=True,\n","            mode='max',\n","            verbose=1\n","        ),\n","\n","        EarlyStopping(\n","            monitor='val_auc',\n","            patience=5,\n","            mode=\"max\",\n","            verbose=1\n","        ),\n","        ReduceLROnPlateau(monitor='val_auc',\n","                          patience=3,\n","                          verbose=1,\n","                          factor=0.5,\n","                          min_lr=0.000001)\n","    ]\n","\n","    #Fine-tune the model\n","    history = model.fit(\n","        X_train,\n","        y_train,\n","        batch_size=batch_size,\n","        epochs=epochs,\n","        validation_data=(X_test, y_test),\n","        callbacks=callbacks,\n","        class_weight=class_weights\n","    )\n","\n","    #Load the best fine-tuned model\n","    best_model = load_model(checkpoint_path)\n","\n","    return best_model, history"]},{"cell_type":"markdown","metadata":{"id":"ukPq1brQfulf"},"source":["## Load trained frozen model"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":11484,"status":"ok","timestamp":1730965459281,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"AmErSBH1QVKV"},"outputs":[],"source":["frozen_model = load_model(\"/content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_no_segmentation.keras\")"]},{"cell_type":"markdown","metadata":{"id":"kDUlUqtsfz0m"},"source":["## Fine tune the frozen model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"VLB96waRfsMM"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - accuracy: 0.4179 - auc: 0.8018 - loss: 3.1816\n","Epoch 1: val_auc improved from -inf to 0.86608, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_no_dullrazor_no_segmentation.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 570ms/step - accuracy: 0.4180 - auc: 0.8019 - loss: 3.1808 - val_accuracy: 0.5360 - val_auc: 0.8661 - val_loss: 1.4594 - learning_rate: 1.0000e-05\n","Epoch 2/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5119 - auc: 0.8572 - loss: 1.6561\n","Epoch 2: val_auc did not improve from 0.86608\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 131ms/step - accuracy: 0.5119 - auc: 0.8572 - loss: 1.6559 - val_accuracy: 0.5155 - val_auc: 0.8619 - val_loss: 1.4981 - learning_rate: 1.0000e-05\n","Epoch 3/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5377 - auc: 0.8765 - loss: 1.2474\n","Epoch 3: val_auc improved from 0.86608 to 0.87730, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_no_dullrazor_no_segmentation.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 143ms/step - accuracy: 0.5377 - auc: 0.8765 - loss: 1.2473 - val_accuracy: 0.5390 - val_auc: 0.8773 - val_loss: 1.3861 - learning_rate: 1.0000e-05\n","Epoch 4/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5660 - auc: 0.8892 - loss: 1.0168\n","Epoch 4: val_auc improved from 0.87730 to 0.88846, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_no_dullrazor_no_segmentation.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 144ms/step - accuracy: 0.5660 - auc: 0.8892 - loss: 1.0168 - val_accuracy: 0.5500 - val_auc: 0.8885 - val_loss: 1.3044 - learning_rate: 1.0000e-05\n","Epoch 5/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5823 - auc: 0.8998 - loss: 0.8539\n","Epoch 5: val_auc improved from 0.88846 to 0.90779, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_no_dullrazor_no_segmentation.keras\n","\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 144ms/step - accuracy: 0.5823 - auc: 0.8998 - loss: 0.8539 - val_accuracy: 0.6114 - val_auc: 0.9078 - val_loss: 1.1562 - learning_rate: 1.0000e-05\n","Epoch 6/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5983 - auc: 0.9092 - loss: 0.7363\n","Epoch 6: val_auc did not improve from 0.90779\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 130ms/step - accuracy: 0.5983 - auc: 0.9092 - loss: 0.7363 - val_accuracy: 0.5839 - val_auc: 0.8956 - val_loss: 1.2395 - learning_rate: 5.0000e-06\n","Epoch 7/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.6095 - auc: 0.9102 - loss: 0.7041\n","Epoch 7: val_auc did not improve from 0.90779\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 128ms/step - accuracy: 0.6095 - auc: 0.9102 - loss: 0.7041 - val_accuracy: 0.5859 - val_auc: 0.8996 - val_loss: 1.2139 - learning_rate: 5.0000e-06\n","Epoch 8/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.6249 - auc: 0.9160 - loss: 0.6418\n","Epoch 8: val_auc did not improve from 0.90779\n","\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 128ms/step - accuracy: 0.6249 - auc: 0.9160 - loss: 0.6418 - val_accuracy: 0.5894 - val_auc: 0.9013 - val_loss: 1.1905 - learning_rate: 5.0000e-06\n","Epoch 9/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.6170 - auc: 0.9165 - loss: 0.6166\n","Epoch 9: val_auc did not improve from 0.90779\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 125ms/step - accuracy: 0.6170 - auc: 0.9165 - loss: 0.6165 - val_accuracy: 0.6004 - val_auc: 0.9054 - val_loss: 1.1596 - learning_rate: 2.5000e-06\n","Epoch 10/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.6440 - auc: 0.9225 - loss: 0.6076\n","Epoch 10: val_auc did not improve from 0.90779\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 125ms/step - accuracy: 0.6440 - auc: 0.9225 - loss: 0.6077 - val_accuracy: 0.6004 - val_auc: 0.9067 - val_loss: 1.1432 - learning_rate: 2.5000e-06\n","Epoch 10: early stopping\n"]}],"source":["fine_tuned_model, history_fined_tune = fine_tune_model(frozen_model, X=X, y_encoded=y_encoded, batch_size = 16, epochs = 100, model_dir=fine_tuned_model_dir)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
