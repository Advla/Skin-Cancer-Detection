{"cells":[{"cell_type":"markdown","metadata":{"id":"oTY2nsttIsSB"},"source":["# DenseNet 201 model for cancer detection on the HAM10000 dataset"]},{"cell_type":"markdown","metadata":{"id":"kGJ7aLO_IyFw"},"source":["## import necessary libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4956,"status":"ok","timestamp":1730939638228,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"xwd96pkvCrkh"},"outputs":[],"source":["import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow.keras.applications import DenseNet201\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.preprocessing import LabelEncoder\n","import matplotlib.pyplot as plt\n","\n","import os\n","import json"]},{"cell_type":"markdown","metadata":{"id":"HLyVeDAj10ul"},"source":["## Load preprocessed dataset (resized 128x128, with segmentation and hair removal, and normalized between 0 and 1)"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":652,"status":"error","timestamp":1730939314201,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"IcFHGVHbCtKO","colab":{"base_uri":"https://localhost:8080/","height":165},"outputId":"103466fa-35d9-4cc1-cdbf-c397a6ba1dd6"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'np' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d4aa534ac8b9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/X_dullrazor_128_otsu.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/y_dullrazor_128_otsu.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}],"source":["X = np.load('/content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/X_dullrazor_128_otsu.npy')\n","y = np.load('/content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/y_dullrazor_128_otsu.npy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V0OKadFyjRIk"},"outputs":[],"source":["def normalize_images_imagenet(X):\n","    \"\"\"\n","    Normalize images using ImageNet mean and std\n","    \"\"\"\n","    #ImageNet normalization\n","    mean = [0.485, 0.456, 0.406]\n","    std = [0.229, 0.224, 0.225]\n","\n","    for i in range(3):\n","        X[:,:,:,i] = (X[:,:,:,i] - mean[i]) / std[i]\n","\n","    return X"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sSFO6IeOhGqz"},"outputs":[],"source":["X = normalize_images_imagenet(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1730899853848,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"h5pyr0FHC2Yq","outputId":"e62973a2-6cbd-4e7c-d7c0-e2b4c82bf001"},"outputs":[{"data":{"text/plain":["(10010, 128, 128, 3)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1730899853849,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"3lx3_1spDGxG","outputId":"3a0fbf7f-430a-4999-c1c4-be4ada5d8105"},"outputs":[{"data":{"text/plain":["(10010,)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["y.shape"]},{"cell_type":"markdown","metadata":{"id":"VZdWYXVNSr_H"},"source":["## Define model directories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4zCV51Q4Sxkj"},"outputs":[],"source":["frozen_model_dir = \"/content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/\"\n","fine_tuned_model_dir = \"/content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/\""]},{"cell_type":"markdown","metadata":{"id":"4dYOsO4oR-hV"},"source":["## Prepare labels with One-Hot encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mY789qwWR8xE"},"outputs":[],"source":["def prepare_labels(labels, model_dir):\n","        \"\"\"Convert string labels to one-hot encoding\"\"\"\n","        #create and fit label encoder\n","        label_encoder = LabelEncoder()\n","        numeric_labels = label_encoder.fit_transform(labels)\n","\n","        #save label encoder classes so we can use them later for interpretation\n","        label_mapping = dict(zip(label_encoder.classes_,\n","                               range(len(label_encoder.classes_))))\n","        with open(os.path.join(model_dir, 'label_mapping_128.json'), 'w') as f:\n","            json.dump(label_mapping, f)\n","\n","        #one-hot encoding the numeric-encoded classes\n","        one_hot_labels = tf.keras.utils.to_categorical(numeric_labels)\n","\n","        #Print mapping for verification\n","        print(\"Label mapping:\")\n","        for label, idx in label_mapping.items():\n","            print(f\"{label}: {idx}\")\n","\n","        return one_hot_labels, label_encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1018,"status":"ok","timestamp":1730899865332,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"usPZTbWrSEYZ","outputId":"434b93d6-f86b-421c-8067-4135b95cc09b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Label mapping:\n","akiec: 0\n","bcc: 1\n","bkl: 2\n","df: 3\n","mel: 4\n","nv: 5\n","vasc: 6\n"]}],"source":["y_encoded, label_encoder = prepare_labels(y, frozen_model_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":770,"status":"ok","timestamp":1730899866733,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"RST_ewYaTngs","outputId":"1d5cc2eb-1a2d-4947-89f5-96e4582acdd0"},"outputs":[{"data":{"text/plain":["array([[0., 0., 1., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 1., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 1., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0.],\n","       [0., 0., 1., 0., 0., 0., 0.]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["y_encoded[0:10]"]},{"cell_type":"markdown","metadata":{"id":"2ujF6rPBLFHx"},"source":["### Handle class imbalance -> weigthed loss"]},{"cell_type":"markdown","metadata":{"id":"PhoIjkCBNBzW"},"source":["first, compute class weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qfdJrYjBLEYJ"},"outputs":[],"source":["#CAREFUL use this function with the training set to prevent data leakage\n","def calculate_class_weights(y_encoded):\n","    \"\"\"\n","    Calculate class weights from original string labels\n","\n","    Parameters:\n","    label_encoder: LabelEncoder object which served to encode the original labels\n","    original_labels: array of original string labels\n","\n","    Returns:\n","    dict: mapping of numerical indices to weights\n","    \"\"\"\n","    #Use label encoder to get numerical labels\n","    numerical_labels = np.argmax(y_encoded, axis=1)\n","\n","    #Calculate weights\n","    weights = compute_class_weight(\n","        class_weight='balanced',\n","        classes=np.unique(numerical_labels),\n","        y=numerical_labels\n","    )\n","\n","    #Create dictionary mapping class indices to weights\n","    class_weights = dict(zip(range(len(weights)), weights))\n","\n","    return class_weights"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1730899876968,"user":{"displayName":"Andréa","userId":"15736105813527561360"},"user_tz":-660},"id":"7AUiUvErYI9j","outputId":"34559bc0-c655-4ff2-c6bd-7c43787f87ee"},"outputs":[{"data":{"text/plain":["{0: 4.386503067484663,\n"," 1: 2.782101167315175,\n"," 2: 1.3035551504102096,\n"," 3: 12.434782608695652,\n"," 4: 1.2848158131176999,\n"," 5: 0.21333731165149933,\n"," 6: 10.070422535211268}"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["#try the function\n","calculate_class_weights(y_encoded)"]},{"cell_type":"markdown","metadata":{"id":"WQ1cxS6pI5mT"},"source":["## We're going to do a two phase training approach:\n","* Initial training with frozen base model\n","* Fine-tuning of the last 30 layers"]},{"cell_type":"markdown","metadata":{"id":"jvOScpjTK906"},"source":["### Create a DenseNet model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n-f18HJYDIb_"},"outputs":[],"source":["def create_densenet_model(num_classes, input_shape=(128, 128, 3)):\n","    \"\"\"\n","    Create a DenseNet201 model with custom top layers for melanoma detection\n","    \"\"\"\n","    #Load the pre-trained DenseNet201 model without top layers\n","    base_model = DenseNet201(\n","        weights='imagenet',\n","        include_top=False,\n","        input_shape=input_shape\n","    )\n","\n","    #Freeze the base model layers\n","    base_model.trainable = False\n","\n","    #Add custom top layers\n","    x = base_model.output\n","    x = Flatten()(x)\n","    x = Dropout(0.25)(x)\n","\n","    x = Dense(512, activation='relu')(x)\n","    x = BatchNormalization()(x) #Good habit apparently, It normalizes the activations of each layer, making their means close to 0 and standard deviations close to 1\n","    x = Dropout(0.5)(x)\n","\n","    x = Dense(256, activation='relu')(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.5)(x)\n","\n","    #Output layer\n","    predictions = Dense(num_classes, activation='softmax')(x)\n","\n","    #Create the full model\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"z6Hh7n8VPDHk"},"source":["## Train model with frozen base DenseNet201"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6S68n2LJrju"},"outputs":[],"source":["def train_model(X, y_encoded, batch_size=16, epochs=50, model_dir='model_checkpoints'):\n","    \"\"\"\n","    Train the model with class weighting and proper checkpoint saving\n","    \"\"\"\n","    #Create model directory if it doesn't exist\n","    os.makedirs(model_dir, exist_ok=True)\n","\n","    #Calculate class weights\n","    class_weights = calculate_class_weights(y_encoded)\n","    print(\"Class weights:\", class_weights)\n","\n","    ##---Data splitting: we want a 75, 20, 5 train/test/validation split\n","    X_train_val, X_test, y_train_val, y_test = train_test_split(\n","        X, y_encoded,\n","        test_size=0.20,\n","        random_state=42, #for reproductibility\n","        stratify=y_encoded\n","    )\n","\n","      #Then split remaining data into train and validation (val is 5% of total)\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X_train_val, y_train_val,\n","        test_size=0.0625,  #0.05/0.80 to get 5% of total data\n","        random_state=42,\n","        stratify=y_train_val\n","    )\n","\n","    #initialte DenseNet model\n","    model = create_densenet_model(num_classes=y_encoded.shape[1])\n","\n","    #compile with optimizers and loss\n","    model.compile(\n","        optimizer=Adam(learning_rate=0.001),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')] #AUC is a very good metric for our problem\n","    )\n","\n","    #Define callbacks\n","    checkpoint_path = os.path.join(model_dir, 'densenet201_ph1_128_dullrazor_segmented.keras')\n","    callbacks = [\n","        ModelCheckpoint( #save best model at each iteration, because the tensorflow built-in functionnality doesn't work\n","            checkpoint_path,\n","            monitor='val_auc',\n","            save_best_only=True,\n","            mode='max',\n","            verbose=1\n","        ),\n","        EarlyStopping( #avoid overfitting\n","            monitor='val_auc', #here we monitor the val_accuracy\n","            patience=6,\n","            mode='max',\n","            verbose=1\n","        ),\n","        #Set a learning rate annealer\n","        ReduceLROnPlateau(monitor='val_auc',\n","                          patience=3,\n","                          verbose=1,\n","                          factor=0.5,\n","                          min_lr=0.00001)\n","    ]\n","\n","    #Train the model\n","    history = model.fit(\n","        X_train,\n","        y_train,\n","        batch_size=batch_size,\n","        epochs=epochs,\n","        validation_data=(X_test, y_test),\n","        callbacks=callbacks,\n","        class_weight=class_weights #WEIGHTED LOSS to address class imbalance !\n","    )\n","\n","    #Load the best model\n","    best_model = load_model(checkpoint_path)\n","\n","    return best_model, history"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"geVcircEQalI","outputId":"aa1f1abc-a6ad-4a89-9174-2338d1ab1e2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Class weights: {0: 4.386503067484663, 1: 2.782101167315175, 2: 1.3035551504102096, 3: 12.434782608695652, 4: 1.2848158131176999, 5: 0.21333731165149933, 6: 10.070422535211268}\n","Epoch 1/50\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2512 - auc: 0.6248 - loss: 2.7377\n","Epoch 1: val_auc improved from -inf to 0.78378, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 196ms/step - accuracy: 0.2513 - auc: 0.6249 - loss: 2.7369 - val_accuracy: 0.4456 - val_auc: 0.7838 - val_loss: 1.6608 - learning_rate: 0.0010\n","Epoch 2/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3676 - auc: 0.7353 - loss: 1.7684\n","Epoch 2: val_auc improved from 0.78378 to 0.81629, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 57ms/step - accuracy: 0.3676 - auc: 0.7353 - loss: 1.7684 - val_accuracy: 0.4665 - val_auc: 0.8163 - val_loss: 1.5011 - learning_rate: 0.0010\n","Epoch 3/50\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4108 - auc: 0.7773 - loss: 1.5159\n","Epoch 3: val_auc improved from 0.81629 to 0.83973, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 57ms/step - accuracy: 0.4109 - auc: 0.7773 - loss: 1.5159 - val_accuracy: 0.5025 - val_auc: 0.8397 - val_loss: 1.3663 - learning_rate: 0.0010\n","Epoch 4/50\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4657 - auc: 0.8196 - loss: 1.2863\n","Epoch 4: val_auc improved from 0.83973 to 0.86403, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_dullrazor_segmented.keras\n","\n","Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 57ms/step - accuracy: 0.4657 - auc: 0.8195 - loss: 1.2864 - val_accuracy: 0.5270 - val_auc: 0.8640 - val_loss: 1.2685 - learning_rate: 0.0010\n","Epoch 5/50\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4930 - auc: 0.8420 - loss: 1.1728\n","Epoch 5: val_auc improved from 0.86403 to 0.88094, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 57ms/step - accuracy: 0.4930 - auc: 0.8420 - loss: 1.1728 - val_accuracy: 0.5669 - val_auc: 0.8809 - val_loss: 1.1864 - learning_rate: 5.0000e-04\n","Epoch 6/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5416 - auc: 0.8648 - loss: 1.0956\n","Epoch 6: val_auc did not improve from 0.88094\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 48ms/step - accuracy: 0.5416 - auc: 0.8648 - loss: 1.0956 - val_accuracy: 0.5095 - val_auc: 0.8616 - val_loss: 1.3318 - learning_rate: 5.0000e-04\n","Epoch 7/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5386 - auc: 0.8694 - loss: 1.0362\n","Epoch 7: val_auc improved from 0.88094 to 0.89556, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_dullrazor_segmented.keras\n","\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 58ms/step - accuracy: 0.5387 - auc: 0.8695 - loss: 1.0361 - val_accuracy: 0.5754 - val_auc: 0.8956 - val_loss: 1.1195 - learning_rate: 5.0000e-04\n","Epoch 8/50\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5716 - auc: 0.8873 - loss: 0.9267\n","Epoch 8: val_auc did not improve from 0.89556\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 48ms/step - accuracy: 0.5716 - auc: 0.8873 - loss: 0.9268 - val_accuracy: 0.5604 - val_auc: 0.8884 - val_loss: 1.1615 - learning_rate: 2.5000e-04\n","Epoch 9/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5768 - auc: 0.8902 - loss: 0.9156\n","Epoch 9: val_auc improved from 0.89556 to 0.89622, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 56ms/step - accuracy: 0.5768 - auc: 0.8902 - loss: 0.9156 - val_accuracy: 0.5784 - val_auc: 0.8962 - val_loss: 1.1217 - learning_rate: 2.5000e-04\n","Epoch 10/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5751 - auc: 0.8942 - loss: 0.8723\n","Epoch 10: val_auc did not improve from 0.89622\n","\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 48ms/step - accuracy: 0.5752 - auc: 0.8942 - loss: 0.8723 - val_accuracy: 0.5604 - val_auc: 0.8847 - val_loss: 1.1817 - learning_rate: 2.5000e-04\n","Epoch 11/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6009 - auc: 0.9019 - loss: 0.8007\n","Epoch 11: val_auc improved from 0.89622 to 0.89977, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 57ms/step - accuracy: 0.6009 - auc: 0.9019 - loss: 0.8007 - val_accuracy: 0.5899 - val_auc: 0.8998 - val_loss: 1.1036 - learning_rate: 1.2500e-04\n","Epoch 12/50\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6056 - auc: 0.9066 - loss: 0.8051\n","Epoch 12: val_auc improved from 0.89977 to 0.90090, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 57ms/step - accuracy: 0.6056 - auc: 0.9066 - loss: 0.8050 - val_accuracy: 0.5784 - val_auc: 0.9009 - val_loss: 1.1017 - learning_rate: 1.2500e-04\n","Epoch 13/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6108 - auc: 0.9107 - loss: 0.7352\n","Epoch 13: val_auc improved from 0.90090 to 0.90443, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_dullrazor_segmented.keras\n","\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 57ms/step - accuracy: 0.6108 - auc: 0.9107 - loss: 0.7352 - val_accuracy: 0.5889 - val_auc: 0.9044 - val_loss: 1.0821 - learning_rate: 1.2500e-04\n","Epoch 14/50\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6225 - auc: 0.9121 - loss: 0.7169\n","Epoch 14: val_auc improved from 0.90443 to 0.90823, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 57ms/step - accuracy: 0.6225 - auc: 0.9121 - loss: 0.7169 - val_accuracy: 0.6004 - val_auc: 0.9082 - val_loss: 1.0580 - learning_rate: 6.2500e-05\n","Epoch 15/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6204 - auc: 0.9146 - loss: 0.7022\n","Epoch 15: val_auc did not improve from 0.90823\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - accuracy: 0.6205 - auc: 0.9146 - loss: 0.7022 - val_accuracy: 0.5939 - val_auc: 0.9052 - val_loss: 1.0833 - learning_rate: 6.2500e-05\n","Epoch 16/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6400 - auc: 0.9191 - loss: 0.6852\n","Epoch 16: val_auc did not improve from 0.90823\n","\n","Epoch 16: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 48ms/step - accuracy: 0.6400 - auc: 0.9191 - loss: 0.6852 - val_accuracy: 0.5964 - val_auc: 0.9058 - val_loss: 1.0815 - learning_rate: 6.2500e-05\n","Epoch 17/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6479 - auc: 0.9233 - loss: 0.6344\n","Epoch 17: val_auc improved from 0.90823 to 0.91077, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 57ms/step - accuracy: 0.6479 - auc: 0.9233 - loss: 0.6345 - val_accuracy: 0.6029 - val_auc: 0.9108 - val_loss: 1.0512 - learning_rate: 3.1250e-05\n","Epoch 18/50\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6555 - auc: 0.9243 - loss: 0.6379\n","Epoch 18: val_auc improved from 0.91077 to 0.91190, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 58ms/step - accuracy: 0.6555 - auc: 0.9243 - loss: 0.6380 - val_accuracy: 0.6029 - val_auc: 0.9119 - val_loss: 1.0447 - learning_rate: 3.1250e-05\n","Epoch 19/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6437 - auc: 0.9243 - loss: 0.6672\n","Epoch 19: val_auc improved from 0.91190 to 0.91227, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_dullrazor_segmented.keras\n","\n","Epoch 19: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 57ms/step - accuracy: 0.6437 - auc: 0.9243 - loss: 0.6672 - val_accuracy: 0.6034 - val_auc: 0.9123 - val_loss: 1.0431 - learning_rate: 3.1250e-05\n","Epoch 20/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6489 - auc: 0.9272 - loss: 0.6176\n","Epoch 20: val_auc improved from 0.91227 to 0.91307, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 57ms/step - accuracy: 0.6489 - auc: 0.9272 - loss: 0.6177 - val_accuracy: 0.6104 - val_auc: 0.9131 - val_loss: 1.0366 - learning_rate: 1.5625e-05\n","Epoch 21/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6491 - auc: 0.9239 - loss: 0.6458\n","Epoch 21: val_auc did not improve from 0.91307\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 48ms/step - accuracy: 0.6491 - auc: 0.9239 - loss: 0.6459 - val_accuracy: 0.6029 - val_auc: 0.9122 - val_loss: 1.0426 - learning_rate: 1.5625e-05\n","Epoch 22/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6400 - auc: 0.9205 - loss: 0.6520\n","Epoch 22: val_auc did not improve from 0.91307\n","\n","Epoch 22: ReduceLROnPlateau reducing learning rate to 1e-05.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 47ms/step - accuracy: 0.6400 - auc: 0.9205 - loss: 0.6520 - val_accuracy: 0.6054 - val_auc: 0.9114 - val_loss: 1.0489 - learning_rate: 1.5625e-05\n","Epoch 23/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6442 - auc: 0.9253 - loss: 0.6506\n","Epoch 23: val_auc did not improve from 0.91307\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 47ms/step - accuracy: 0.6442 - auc: 0.9253 - loss: 0.6506 - val_accuracy: 0.6019 - val_auc: 0.9097 - val_loss: 1.0589 - learning_rate: 1.0000e-05\n","Epoch 24/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6525 - auc: 0.9231 - loss: 0.6132\n","Epoch 24: val_auc did not improve from 0.91307\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 48ms/step - accuracy: 0.6525 - auc: 0.9231 - loss: 0.6133 - val_accuracy: 0.6054 - val_auc: 0.9115 - val_loss: 1.0473 - learning_rate: 1.0000e-05\n","Epoch 25/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6468 - auc: 0.9247 - loss: 0.6719\n","Epoch 25: val_auc did not improve from 0.91307\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 48ms/step - accuracy: 0.6469 - auc: 0.9247 - loss: 0.6718 - val_accuracy: 0.6044 - val_auc: 0.9108 - val_loss: 1.0526 - learning_rate: 1.0000e-05\n","Epoch 26/50\n","\u001b[1m469/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6521 - auc: 0.9289 - loss: 0.5917\n","Epoch 26: val_auc did not improve from 0.91307\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.6521 - auc: 0.9289 - loss: 0.5918 - val_accuracy: 0.6044 - val_auc: 0.9095 - val_loss: 1.0609 - learning_rate: 1.0000e-05\n","Epoch 26: early stopping\n"]}],"source":["best_model_frozen, history_frozen = train_model(X=X, y_encoded=y_encoded, batch_size = 16, epochs = 50, model_dir=\"/content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/\")"]},{"cell_type":"markdown","metadata":{"id":"A-DKUcZKPQZ8"},"source":["## Fine tune the last 30 layers of the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4lWy8a05O7Wd"},"outputs":[],"source":["def fine_tune_model(model, X, y_encoded, batch_size=16, epochs=30, model_dir='model_checkpoints'):\n","    \"\"\"\n","    Fine-tune the model from phase A with class weighting and proper checkpoint saving\n","    \"\"\"\n","    #Create model directory if it doesn't exist\n","    os.makedirs(model_dir, exist_ok=True)\n","\n","    #Calculate class weights\n","    class_weights = calculate_class_weights(y_encoded)\n","\n","    ##---Data splitting: we want a 75, 20, 5 train/test/validation split\n","    X_train_val, X_test, y_train_val, y_test = train_test_split(\n","        X, y_encoded,\n","        test_size=0.20,\n","        random_state=42, #for reproductibility\n","        stratify=y_encoded\n","    )\n","\n","      #Then split remaining data into train and validation (val is 5% of total)\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X_train_val, y_train_val,\n","        test_size=0.0625,  #0.05/0.80 to get 5% of total data\n","        random_state=42,\n","        stratify=y_train_val\n","    )\n","\n","    ##---IMPORTANT PART: Which layers do we unfreeze ?--\n","    #Unfreeze last two dense blocks | Gessert et al. (2020) found best performance doing this.\n","    for layer in model.layers:\n","      if any(x in layer.name for x in ['conv5', 'block4', 'conv4', 'block3']):\n","          layer.trainable = True\n","\n","    #Recompile with a lower learning rate\n","    model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), ##Much lower learning rate for fine-tuning\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n","    )\n","\n","    #Define callbacks\n","    checkpoint_path = os.path.join(model_dir, 'densenet201_ph2_128_dullrazor_segmented.keras')\n","    callbacks = [\n","        ModelCheckpoint(\n","            checkpoint_path,\n","            monitor='val_auc',\n","            save_best_only=True,\n","            mode='max',\n","            verbose=1\n","        ),\n","        EarlyStopping(\n","            monitor='val_auc',\n","            patience=5,\n","            mode='max',\n","            verbose=1\n","        ),\n","        # Set a learning rate annealer\n","        ReduceLROnPlateau(monitor='val_auc',\n","                          patience=3,\n","                          verbose=1,\n","                          factor=0.5,\n","                          min_lr=0.000001)\n","    ]\n","\n","    #Fine-tune the model\n","    history = model.fit(\n","        X_train,\n","        y_train,\n","        batch_size=batch_size,\n","        epochs=epochs,\n","        validation_data=(X_test, y_test),\n","        callbacks=callbacks,\n","        class_weight=class_weights\n","    )\n","\n","    #Load the best fine-tuned model\n","    best_model = load_model(checkpoint_path)\n","\n","    return best_model, history"]},{"cell_type":"markdown","metadata":{"id":"ukPq1brQfulf"},"source":["## Load trained frozen model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AmErSBH1QVKV"},"outputs":[],"source":["frozen_model = load_model(\"/content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Frozen_model/densenet201_ph1_128_dullrazor_segmented.keras\")"]},{"cell_type":"markdown","metadata":{"id":"kDUlUqtsfz0m"},"source":["## Fine tune the frozen model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Doc_OqlxKqZ-","outputId":"4a1ad17f-fd3b-4b09-d009-509f7b821f78"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.5135 - auc: 0.8572 - loss: 1.4315\n","Epoch 1: val_auc improved from -inf to 0.86412, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 471ms/step - accuracy: 0.5134 - auc: 0.8572 - loss: 1.4314 - val_accuracy: 0.4930 - val_auc: 0.8641 - val_loss: 1.3690 - learning_rate: 1.0000e-05\n","Epoch 2/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.5354 - auc: 0.8762 - loss: 1.0235\n","Epoch 2: val_auc improved from 0.86412 to 0.87755, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 122ms/step - accuracy: 0.5354 - auc: 0.8763 - loss: 1.0235 - val_accuracy: 0.5145 - val_auc: 0.8775 - val_loss: 1.2759 - learning_rate: 1.0000e-05\n","Epoch 3/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.5651 - auc: 0.8918 - loss: 0.8215 \n","Epoch 3: val_auc improved from 0.87755 to 0.88290, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 122ms/step - accuracy: 0.5651 - auc: 0.8918 - loss: 0.8215 - val_accuracy: 0.5250 - val_auc: 0.8829 - val_loss: 1.2615 - learning_rate: 1.0000e-05\n","Epoch 4/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.5750 - auc: 0.8977 - loss: 0.7083\n","Epoch 4: val_auc improved from 0.88290 to 0.89240, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_dullrazor_segmented.keras\n","\n","Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.5750 - auc: 0.8977 - loss: 0.7083 - val_accuracy: 0.5564 - val_auc: 0.8924 - val_loss: 1.1833 - learning_rate: 1.0000e-05\n","Epoch 5/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.6099 - auc: 0.9125 - loss: 0.6464\n","Epoch 5: val_auc improved from 0.89240 to 0.89541, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.6098 - auc: 0.9125 - loss: 0.6464 - val_accuracy: 0.5579 - val_auc: 0.8954 - val_loss: 1.1698 - learning_rate: 5.0000e-06\n","Epoch 6/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.6168 - auc: 0.9121 - loss: 0.6217 \n","Epoch 6: val_auc improved from 0.89541 to 0.89957, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.6168 - auc: 0.9121 - loss: 0.6217 - val_accuracy: 0.5669 - val_auc: 0.8996 - val_loss: 1.1445 - learning_rate: 5.0000e-06\n","Epoch 7/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.6355 - auc: 0.9218 - loss: 0.5609\n","Epoch 7: val_auc improved from 0.89957 to 0.90044, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_dullrazor_segmented.keras\n","\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 122ms/step - accuracy: 0.6355 - auc: 0.9218 - loss: 0.5609 - val_accuracy: 0.5704 - val_auc: 0.9004 - val_loss: 1.1419 - learning_rate: 5.0000e-06\n","Epoch 8/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.6413 - auc: 0.9238 - loss: 0.5384\n","Epoch 8: val_auc did not improve from 0.90044\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 108ms/step - accuracy: 0.6413 - auc: 0.9238 - loss: 0.5384 - val_accuracy: 0.5644 - val_auc: 0.8980 - val_loss: 1.1579 - learning_rate: 2.5000e-06\n","Epoch 9/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6470 - auc: 0.9249 - loss: 0.5317\n","Epoch 9: val_auc improved from 0.90044 to 0.90480, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 119ms/step - accuracy: 0.6470 - auc: 0.9249 - loss: 0.5316 - val_accuracy: 0.5784 - val_auc: 0.9048 - val_loss: 1.1153 - learning_rate: 2.5000e-06\n","Epoch 10/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.6520 - auc: 0.9306 - loss: 0.4787\n","Epoch 10: val_auc did not improve from 0.90480\n","\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 108ms/step - accuracy: 0.6520 - auc: 0.9306 - loss: 0.4788 - val_accuracy: 0.5759 - val_auc: 0.9037 - val_loss: 1.1227 - learning_rate: 2.5000e-06\n","Epoch 11/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6534 - auc: 0.9303 - loss: 0.4890\n","Epoch 11: val_auc improved from 0.90480 to 0.90728, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 118ms/step - accuracy: 0.6534 - auc: 0.9303 - loss: 0.4890 - val_accuracy: 0.5844 - val_auc: 0.9073 - val_loss: 1.0982 - learning_rate: 1.2500e-06\n","Epoch 12/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.6618 - auc: 0.9305 - loss: 0.4489\n","Epoch 12: val_auc did not improve from 0.90728\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 108ms/step - accuracy: 0.6618 - auc: 0.9305 - loss: 0.4489 - val_accuracy: 0.5854 - val_auc: 0.9063 - val_loss: 1.1071 - learning_rate: 1.2500e-06\n","Epoch 13/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.6628 - auc: 0.9323 - loss: 0.4536\n","Epoch 13: val_auc did not improve from 0.90728\n","\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-06.\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 109ms/step - accuracy: 0.6628 - auc: 0.9323 - loss: 0.4536 - val_accuracy: 0.5809 - val_auc: 0.9055 - val_loss: 1.1077 - learning_rate: 1.2500e-06\n","Epoch 14/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.6823 - auc: 0.9374 - loss: 0.4236\n","Epoch 14: val_auc did not improve from 0.90728\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 108ms/step - accuracy: 0.6823 - auc: 0.9374 - loss: 0.4236 - val_accuracy: 0.5849 - val_auc: 0.9062 - val_loss: 1.1052 - learning_rate: 1.0000e-06\n","Epoch 15/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.6889 - auc: 0.9384 - loss: 0.4198\n","Epoch 15: val_auc improved from 0.90728 to 0.90974, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 120ms/step - accuracy: 0.6889 - auc: 0.9384 - loss: 0.4199 - val_accuracy: 0.5929 - val_auc: 0.9097 - val_loss: 1.0841 - learning_rate: 1.0000e-06\n","Epoch 16/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.6797 - auc: 0.9367 - loss: 0.4285\n","Epoch 16: val_auc improved from 0.90974 to 0.91059, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 122ms/step - accuracy: 0.6798 - auc: 0.9367 - loss: 0.4285 - val_accuracy: 0.5924 - val_auc: 0.9106 - val_loss: 1.0740 - learning_rate: 1.0000e-06\n","Epoch 17/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.6841 - auc: 0.9385 - loss: 0.4132\n","Epoch 17: val_auc did not improve from 0.91059\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 110ms/step - accuracy: 0.6841 - auc: 0.9385 - loss: 0.4132 - val_accuracy: 0.5919 - val_auc: 0.9085 - val_loss: 1.0896 - learning_rate: 1.0000e-06\n","Epoch 18/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.6932 - auc: 0.9397 - loss: 0.4174\n","Epoch 18: val_auc did not improve from 0.91059\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 108ms/step - accuracy: 0.6932 - auc: 0.9397 - loss: 0.4174 - val_accuracy: 0.5899 - val_auc: 0.9093 - val_loss: 1.0891 - learning_rate: 1.0000e-06\n","Epoch 19/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.6882 - auc: 0.9419 - loss: 0.4131\n","Epoch 19: val_auc did not improve from 0.91059\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 109ms/step - accuracy: 0.6882 - auc: 0.9419 - loss: 0.4130 - val_accuracy: 0.5914 - val_auc: 0.9080 - val_loss: 1.0954 - learning_rate: 1.0000e-06\n","Epoch 20/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.6824 - auc: 0.9365 - loss: 0.3945\n","Epoch 20: val_auc did not improve from 0.91059\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 109ms/step - accuracy: 0.6824 - auc: 0.9365 - loss: 0.3945 - val_accuracy: 0.5859 - val_auc: 0.9072 - val_loss: 1.0993 - learning_rate: 1.0000e-06\n","Epoch 21/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7003 - auc: 0.9448 - loss: 0.3958\n","Epoch 21: val_auc improved from 0.91059 to 0.91189, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.7003 - auc: 0.9448 - loss: 0.3958 - val_accuracy: 0.5969 - val_auc: 0.9119 - val_loss: 1.0671 - learning_rate: 1.0000e-06\n","Epoch 22/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.6967 - auc: 0.9437 - loss: 0.3766\n","Epoch 22: val_auc improved from 0.91189 to 0.91273, saving model to /content/drive/MyDrive/Project 36100 - Andrea, Monika, Yamuna/Assignment Stage 2/Fine_tuned_model/densenet201_ph2_128_dullrazor_segmented.keras\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 121ms/step - accuracy: 0.6967 - auc: 0.9437 - loss: 0.3766 - val_accuracy: 0.6009 - val_auc: 0.9127 - val_loss: 1.0627 - learning_rate: 1.0000e-06\n","Epoch 23/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.6957 - auc: 0.9432 - loss: 0.3901\n","Epoch 23: val_auc did not improve from 0.91273\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 108ms/step - accuracy: 0.6957 - auc: 0.9432 - loss: 0.3900 - val_accuracy: 0.5884 - val_auc: 0.9084 - val_loss: 1.0943 - learning_rate: 1.0000e-06\n","Epoch 24/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7021 - auc: 0.9462 - loss: 0.3761\n","Epoch 24: val_auc did not improve from 0.91273\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 107ms/step - accuracy: 0.7021 - auc: 0.9462 - loss: 0.3761 - val_accuracy: 0.5934 - val_auc: 0.9087 - val_loss: 1.0918 - learning_rate: 1.0000e-06\n","Epoch 25/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7119 - auc: 0.9455 - loss: 0.3676\n","Epoch 25: val_auc did not improve from 0.91273\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 108ms/step - accuracy: 0.7119 - auc: 0.9455 - loss: 0.3676 - val_accuracy: 0.6009 - val_auc: 0.9125 - val_loss: 1.0652 - learning_rate: 1.0000e-06\n","Epoch 26/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7120 - auc: 0.9475 - loss: 0.3590\n","Epoch 26: val_auc did not improve from 0.91273\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 107ms/step - accuracy: 0.7120 - auc: 0.9475 - loss: 0.3590 - val_accuracy: 0.5999 - val_auc: 0.9120 - val_loss: 1.0699 - learning_rate: 1.0000e-06\n","Epoch 27/100\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7053 - auc: 0.9463 - loss: 0.3748\n","Epoch 27: val_auc did not improve from 0.91273\n","\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 106ms/step - accuracy: 0.7053 - auc: 0.9463 - loss: 0.3747 - val_accuracy: 0.5994 - val_auc: 0.9117 - val_loss: 1.0689 - learning_rate: 1.0000e-06\n","Epoch 27: early stopping\n"]}],"source":["fine_tuned_model, history_fined_tune = fine_tune_model(frozen_model, X=X, y_encoded=y_encoded, batch_size = 16, epochs = 100, model_dir=fine_tuned_model_dir)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1VGFz7pPcJcRkzFkslVSxNTmBB23vpyd3","timestamp":1730711226660},{"file_id":"16KjjNuuokIVAqqGwTUaLv48A-b0oyp7B","timestamp":1730702037561}],"mount_file_id":"1wzdmJ6074PeB5QquZrZoLsE2-tFkQvrC","authorship_tag":"ABX9TyNJpZGvW7J3OM072KmhpWaH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}