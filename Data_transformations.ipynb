{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1C6gZnibzAy"
      },
      "source": [
        "# Skin Cancer detection and classification using HAM10000 dataset\n",
        "Submitted by **Andrea DAVILA**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DviLskf-cFzS"
      },
      "source": [
        "link to the HAM10000's kaggle page : https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000/data?select=HAM10000_images_part_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNIjLjWq8wi2"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN_WBJ7scYWf"
      },
      "source": [
        "## I. Data Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT5d8CjzdpPO"
      },
      "source": [
        "### Importing the dataset from Kaggle's API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfn3XuMTbrhe",
        "outputId": "3dd9fd8c-937d-4534-d2e6-06cb7e9f0bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "Downloading skin-cancer-mnist-ham10000.zip to /content\n",
            "100% 5.20G/5.20G [02:16<00:00, 42.1MB/s]\n",
            "100% 5.20G/5.20G [02:16<00:00, 41.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "!kaggle datasets download -d kmader/skin-cancer-mnist-ham10000\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/content/skin-cancer-mnist-ham10000.zip', 'r') #don't hesitate to right click on the zip file --> \"copy path\" and paste it here\n",
        "zip_ref.extractall('/content') #destination of the unzipped file\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0WiGlZaebeQ"
      },
      "source": [
        "### Read metadata csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8E5JlhgVRWF",
        "outputId": "2ac1b572-0e19-416e-b13b-809d8e4341f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ibt1bZnxefkD"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/HAM10000_metadata.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--NdNkUpfZQw"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "727tqMWOodyK"
      },
      "source": [
        "## II. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHic1yidqCiQ"
      },
      "source": [
        "### Hair removal : we'll use the DullRazor algorithm.\n",
        "function adapted from https://github.com/BlueDokk/Dullrazor-algorithm/blob/main/ISIC_0031023.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQuyCBYXTXvs"
      },
      "outputs": [],
      "source": [
        "def dullrazor(image_path):\n",
        "  \"\"\"\n",
        "  Applies the dull razor hair removal algorithm to an RGB image.\n",
        "\n",
        "    Args:\n",
        "        image_path (string): the path to the image file.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The image with the hair removed (450, 600, 3) shaped.\n",
        "\n",
        "    Example:\n",
        "        dullrazor(image_rgb) returns an rgb image with the hair removed.\n",
        "  \"\"\"\n",
        "\n",
        "  image=cv2.imread(image_path,cv2.IMREAD_COLOR) #image is read in BGR\n",
        "  #to avoid the dermoscopy frame\n",
        "  image=image[40:400,40:550]\n",
        "  grayScale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY )\n",
        "  #Black hat filter\n",
        "  kernel = cv2.getStructuringElement(1,(9,9))\n",
        "  blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n",
        "  #Gaussian filter\n",
        "  bhg= cv2.GaussianBlur(blackhat,(3,3),cv2.BORDER_DEFAULT)\n",
        "  #Binary thresholding (MASK)\n",
        "  ret,mask = cv2.threshold(bhg,10,255,cv2.THRESH_BINARY)\n",
        "  #Replace pixels of the mask\n",
        "  dst = cv2.inpaint(image, mask, 6, cv2.INPAINT_TELEA)\n",
        "  #retransform the image to RGB\n",
        "  dullrazor_image = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  return dullrazor_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEXxbHqOL5Ly"
      },
      "source": [
        "### Resize image to 128x128 (DenseNet input format, good for compuational efficiency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXkvMu3FFNy9"
      },
      "outputs": [],
      "source": [
        "def resize_image(image, target_size=(128, 128)):\n",
        "    \"\"\"\n",
        "    Resizes image to target size without black bars.\n",
        "    \"\"\"\n",
        "    resized = cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)\n",
        "    return resized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrNONb936TgW"
      },
      "source": [
        "### Lesion segmentation using Otsu's thresholding method\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NY5nzkkj8c5N"
      },
      "outputs": [],
      "source": [
        "def otsu(hair_removed):\n",
        "    \"\"\"\n",
        "    Applies improved Otsu's thresholding with morphological operations to clean up segmentation.\n",
        "\n",
        "    Args:\n",
        "        hair_removed (numpy.ndarray): the RGB image with the hair removed\n",
        "\n",
        "    Returns:\n",
        "        tuple: a tuple containing the binary mask and the segmented image.\n",
        "    \"\"\"\n",
        "    #Get red channel\n",
        "    red_channel = hair_removed[:, :, 0]\n",
        "\n",
        "\n",
        "    ##---Otsu's Thresholding part---\n",
        "      #-preparation->Apply Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(red_channel, (5, 5), 0)\n",
        "\n",
        "      #Apply Otsu's thresholding\n",
        "    _, otsu_thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    ##--Morphological operations to clean up the mask--\n",
        "      #Create circular kernel\n",
        "    kernel_size = 30\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
        "\n",
        "      # 1. remove small noise objects (remeber that the part of interest in BLACK not WHITE !!!!!!!!!)\n",
        "      #here we dilate the surrounding to erase the small noise, then we erode to recover the original mask.\n",
        "    closing = cv2.morphologyEx(otsu_thresh, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "      # 2. Remove holes in the lesion\n",
        "    kernel_size = 50\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
        "    opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    kernel_size = 10\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
        "    erode = cv2.morphologyEx(opening, cv2.MORPH_ERODE, kernel)\n",
        "\n",
        "    ##--Build convex hull of the remaining parts for weird moles--\n",
        "      #Find contours in the binary image\n",
        "    contours, _ = cv2.findContours(~opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "      #Create an empty mask\n",
        "    hull_mask = np.zeros_like(opening)\n",
        "\n",
        "      #Find the convex hull of the contours\n",
        "    all_points = np.vstack([cont.squeeze() for cont in contours])\n",
        "    hull = cv2.convexHull(all_points)\n",
        "\n",
        "      #Draw the convex hull on the mask\n",
        "    cv2.drawContours(hull_mask, [hull], -1, (255, 255, 255), -1)\n",
        "\n",
        "    ##--Apply the hull mask to the original image--\n",
        "    black_pixel_mask = ~hull_mask == 0\n",
        "    #black_pixel_mask = erode == 0\n",
        "    black_pixels_image = np.zeros_like(hair_removed)\n",
        "    black_pixels_image[black_pixel_mask] = hair_removed[black_pixel_mask]\n",
        "\n",
        "    return erode, black_pixels_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28y7yEyuZNJx"
      },
      "source": [
        "## Applying the transformations to all the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6_eieBwPbUV"
      },
      "source": [
        "Delete the few problematic images (error when segmenting) in order to have the exact same splits at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UNqbJhgM6ru"
      },
      "outputs": [],
      "source": [
        "#delete problematic images (did not manage to process them, those generated errors)\n",
        "os.remove(\"/content/ham10000_images_part_1/ISIC_0025610.jpg\")\n",
        "os.remove(\"/content/ham10000_images_part_1/ISIC_0024947.jpg\")\n",
        "os.remove(\"/content/ham10000_images_part_1/ISIC_0027979.jpg\")\n",
        "os.remove(\"/content/ham10000_images_part_2/ISIC_0031449.jpg\")\n",
        "os.remove(\"/content/ham10000_images_part_2/ISIC_0030655.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwkBnUEv96SC"
      },
      "source": [
        "## resize the hole dataset to 128x128x3 without dullrazor and Otsu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s00_Srzd96SC"
      },
      "outputs": [],
      "source": [
        "def resize_dataset(target_size, filepath_dict, df):\n",
        "    \"\"\"\n",
        "    Process images using the segment function and save them to specified output directory\n",
        "\n",
        "    Args:\n",
        "        filepath_dict (dict): Dictionary with filenames as keys and file paths as values\n",
        "        df (pandas.DataFrame): DataFrame containing image labels\n",
        "\n",
        "    Returns:\n",
        "        tuple: Lists of processed images (X), corresponding labels (y) and the list of images we failed to process (failed_images)\n",
        "    \"\"\"\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    failed_images = []\n",
        "\n",
        "    for filename in tqdm(filepath_dict.keys()):\n",
        "        try:\n",
        "            #Process image\n",
        "            image=cv2.imread(filepath_dict[filename], cv2.IMREAD_COLOR) #image is read in BGR\n",
        "            #to avoid the dermoscopy frame\n",
        "            image=image[40:400,40:550]\n",
        "            #resize img\n",
        "            processed_img = resize_image(image, target_size)\n",
        "\n",
        "            #Append to lists (keep RGB format for X)\n",
        "            X.append(processed_img)  #Original RGB format\n",
        "            y.append(df[df['image_id'] == filename.split('.')[0]]['dx'].values[0])\n",
        "\n",
        "        except cv2.error as e:\n",
        "            print(f\"OpenCV error processing {filename}: {str(e)}\")\n",
        "            failed_images.append((filename, \"OpenCV error\"))\n",
        "            continue\n",
        "\n",
        "        except IOError as e:\n",
        "            print(f\"IO error processing {filename}: {str(e)}\")\n",
        "            failed_images.append((filename, \"IO error\"))\n",
        "            continue\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error processing {filename}: {str(e)}\")\n",
        "            failed_images.append((filename, \"Unexpected error\"))\n",
        "            continue\n",
        "      # Print summary\n",
        "    print(f\"\\nProcessing completed:\")\n",
        "    print(f\"Successfully processed: {len(X)} images\")\n",
        "    print(f\"Failed to process: {len(failed_images)} images\")\n",
        "\n",
        "    if failed_images:\n",
        "        print(\"\\nFailed images:\")\n",
        "        for img, error_type in failed_images:\n",
        "            print(f\"- {img}: {error_type}\")\n",
        "\n",
        "    return X, y, failed_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wrf4KuNl96SC",
        "outputId": "e9f04dcb-20ae-484d-e933-99f971290ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10010/10010 [02:31<00:00, 65.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing completed:\n",
            "Successfully processed: 10010 images\n",
            "Failed to process: 0 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "filepath = {}\n",
        "directory1 = \"/content/ham10000_images_part_1\"\n",
        "directory2 = \"/content/ham10000_images_part_2\"\n",
        "\n",
        "#Get file list and path to each image\n",
        "for filename in os.listdir(directory1):\n",
        "    filepath[filename] = os.path.join(directory1, filename)\n",
        "\n",
        "for filename in os.listdir(directory2):\n",
        "    filepath[filename] = os.path.join(directory2, filename)\n",
        "\n",
        "#Process images and get data\n",
        "X, y, failed_images = resize_dataset(target_size=(128, 128), filepath_dict=filepath, df=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2hswP8696SD"
      },
      "outputs": [],
      "source": [
        "#Save the arrays\n",
        "np.save('/content/drive/MyDrive/Project 36100 - Andrea/Assignment Stage 2/X_NO_dullrazor_NO_segmentation_128.npy', X)\n",
        "np.save('/content/drive/MyDrive/Project 36100 - Andrea/Assignment Stage 2/y_NO_dullrazor_NO_segmentation_128.npy', y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cBzfY6gxnV7"
      },
      "source": [
        "## Apply dullrazor + resizing to the hole dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oR5jeMxxi09"
      },
      "outputs": [],
      "source": [
        "def hair_removal_and_resize(target_size, filepath_dict, df):\n",
        "    \"\"\"\n",
        "    Process images using the segment function and save them to specified output directory\n",
        "\n",
        "    Args:\n",
        "        filepath_dict (dict): Dictionary with filenames as keys and file paths as values\n",
        "        df (pandas.DataFrame): DataFrame containing image labels\n",
        "\n",
        "    Returns:\n",
        "        tuple: Lists of processed images (X), corresponding labels (y) and the list of images we failed to process (failed_images)\n",
        "    \"\"\"\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    failed_images = []\n",
        "\n",
        "    for filename in tqdm(filepath_dict.keys()):\n",
        "        try:\n",
        "            #Process image\n",
        "            processed_img = dullrazor(filepath_dict[filename])\n",
        "            processed_img = resize_image(processed_img, target_size)\n",
        "\n",
        "            #Append to lists (keep RGB format for X)\n",
        "            X.append(processed_img)  #Original RGB format\n",
        "            y.append(df[df['image_id'] == filename.split('.')[0]]['dx'].values[0])\n",
        "\n",
        "        except cv2.error as e:\n",
        "            print(f\"OpenCV error processing {filename}: {str(e)}\")\n",
        "            failed_images.append((filename, \"OpenCV error\"))\n",
        "            continue\n",
        "\n",
        "        except IOError as e:\n",
        "            print(f\"IO error processing {filename}: {str(e)}\")\n",
        "            failed_images.append((filename, \"IO error\"))\n",
        "            continue\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error processing {filename}: {str(e)}\")\n",
        "            failed_images.append((filename, \"Unexpected error\"))\n",
        "            continue\n",
        "      # Print summary\n",
        "    print(f\"\\nProcessing completed:\")\n",
        "    print(f\"Successfully processed: {len(X)} images\")\n",
        "    print(f\"Failed to process: {len(failed_images)} images\")\n",
        "\n",
        "    if failed_images:\n",
        "        print(\"\\nFailed images:\")\n",
        "        for img, error_type in failed_images:\n",
        "            print(f\"- {img}: {error_type}\")\n",
        "\n",
        "    return X, y, failed_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkaALZzo1KVU"
      },
      "outputs": [],
      "source": [
        "filepath = {}\n",
        "directory1 = \"/content/ham10000_images_part_1\"\n",
        "directory2 = \"/content/ham10000_images_part_2\"\n",
        "\n",
        "#Get file list and path to each image\n",
        "for filename in os.listdir(directory1):\n",
        "    filepath[filename] = os.path.join(directory1, filename)\n",
        "\n",
        "for filename in os.listdir(directory2):\n",
        "    filepath[filename] = os.path.join(directory2, filename)\n",
        "\n",
        "#Process images and get data\n",
        "X, y, failed_images = hair_removal_and_resize(target_size=(128, 128), filepath_dict=filepath, df=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TybmoQbpyhMK"
      },
      "outputs": [],
      "source": [
        "#Save the arrays\n",
        "np.save('/content/drive/MyDrive/Project 36100 - Andrea/Assignment Stage 2/X_hair_removal_NO_segmentation_128.npy', X)\n",
        "np.save('/content/drive/MyDrive/Project 36100 - Andrea/Assignment Stage 2/y_hair_removal_NO_segmentation_128.npy', y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx02Jg7An3yQ"
      },
      "source": [
        "## Apply DullRazor + Otsu + resizing (128x128) transformations to the whole dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dym5gsJLuO0p"
      },
      "source": [
        "### resize image and segment function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_IxZA5Jum2p"
      },
      "outputs": [],
      "source": [
        "def segment_resize(file_path):\n",
        "  \"\"\"applies hair removal and segmentation operations on the image at the file_path\"\"\"\n",
        "  target_size=(128, 128)\n",
        "  hair_removed = dullrazor(file_path)\n",
        "  _, segmented_image = otsu(hair_removed)\n",
        "  resized_img = resize_image(segmented_image, target_size)\n",
        "  return resized_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqEOIkxt9CsN"
      },
      "source": [
        "## Save Data into usable format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pfOa5TjBeyo"
      },
      "outputs": [],
      "source": [
        "def hair_removal_segment_images(filepath_dict, df):\n",
        "    \"\"\"\n",
        "    Process images using the segment function and dullrazor and save them to specified output directory\n",
        "\n",
        "    Args:\n",
        "        filepath_dict (dict): Dictionary with filenames as keys and file paths as values\n",
        "        df (pandas.DataFrame): DataFrame containing image labels\n",
        "        output_dir (str): Directory to save processed images\n",
        "        segment_func (function): Function to process the images\n",
        "\n",
        "    Returns:\n",
        "        tuple: Lists of processed images (X) and corresponding labels (y)\n",
        "    \"\"\"\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    failed_images = []\n",
        "\n",
        "    for filename in tqdm(filepath_dict.keys()):\n",
        "        try:\n",
        "            #Process image\n",
        "            processed_img = segment_resize(filepath_dict[filename])\n",
        "\n",
        "            #Append to lists (keep RGB format for X)\n",
        "            X.append(processed_img/255)  #normalizing the image\n",
        "            y.append(df[df['image_id'] == filename.split('.')[0]]['dx'].values[0])\n",
        "\n",
        "        except cv2.error as e:\n",
        "            print(f\"OpenCV error processing {filename}: {str(e)}\")\n",
        "            failed_images.append((filename, \"OpenCV error\"))\n",
        "            continue\n",
        "\n",
        "        except IOError as e:\n",
        "            print(f\"IO error processing {filename}: {str(e)}\")\n",
        "            failed_images.append((filename, \"IO error\"))\n",
        "            continue\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error processing {filename}: {str(e)}\")\n",
        "            failed_images.append((filename, \"Unexpected error\"))\n",
        "            continue\n",
        "      # Print summary\n",
        "    print(f\"\\nProcessing completed:\")\n",
        "    print(f\"Successfully processed: {len(X)} images\")\n",
        "    print(f\"Failed to process: {len(failed_images)} images\")\n",
        "\n",
        "    if failed_images:\n",
        "        print(\"\\nFailed images:\")\n",
        "        for img, error_type in failed_images:\n",
        "            print(f\"- {img}: {error_type}\")\n",
        "\n",
        "    return X, y, failed_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0BAXhgRB1y1"
      },
      "outputs": [],
      "source": [
        "#Example usage:\n",
        "filepath = {}\n",
        "directory1 = \"/content/ham10000_images_part_1\"\n",
        "directory2 = \"/content/ham10000_images_part_2\"\n",
        "\n",
        "#Get file list and path to each image\n",
        "for filename in os.listdir(directory1):\n",
        "    filepath[filename] = os.path.join(directory1, filename)\n",
        "\n",
        "for filename in os.listdir(directory2):\n",
        "    filepath[filename] = os.path.join(directory2, filename)\n",
        "\n",
        "#Process images and get data\n",
        "X, y, failed_images = hair_removal_segment_images(filepath, df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K77Q-1sK9pD_"
      },
      "outputs": [],
      "source": [
        "#Save the arrays\n",
        "np.save('/content/drive/MyDrive/Project 36100 - Andrea/Assignment Stage 2/X_dullrazor_128_otsu.npy', X)\n",
        "np.save('/content/drive/MyDrive/Project 36100 - Andrea/Assignment Stage 2/y_dullrazor_128_otsu.npy', y)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}